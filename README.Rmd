---
title: "2020 Russian constitutional referendum"
author: "Andi (almost@gmail.com, @[inductivestep](https://twitter.com/InductiveStep))"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: github_document
---

Using `rvest` to scrape the 2020 Russian constitutional referendum results from Wikipedia, do some sums, and plot them on a choropleth (`raster` and `ggplot`).

### Load packages

```{r message=FALSE}
library(rvest)
library(car)
library(tidyverse)
library(kableExtra)
library(viridis)
```


### Read in Wikipedia page

```{r}
wp_page <- read_html("https://en.wikipedia.org/w/index.php?title=2020_Russian_constitutional_referendum&oldid=966242800")
```

### Grab the table

```{r}
results <- wp_page %>%
  html_node(xpath = '//*[@id="mw-content-text"]/div/table[10]') %>%
  html_table(fill = TRUE)
names(results) <- c("Region", "Votes_Yes", "Perc_Yes", "Votes_No", "Perc_No")
```

```{r eval = F}
View(results)
```

### Cleaning

Remove an empty row and other stuff...

```{r}
res_clean <- results %>%
  subset(!Region %in% c("",
                        "Source: CEC",
                        "Region"))
```

Remove the thousand separator commas.

```{r}
res_clean %>%
  mutate_at(vars(starts_with("Votes")),
            ~ gsub(",", "", .)) -> res_clean
```

Now transform all the numbers to numerics.

```{r}
res_clean %>%
  mutate_at(vars(!matches("Region")),
            as.numeric) -> res_clean
```

Remove those percentages:

```{r}
res_clean %>%
  dplyr::select(-c(starts_with("Perc"))) -> res_clean
```

Have a peek:

```{r eval = F}
View(res_clean)
```

### 'rithmetic

Total sums:

```{r}
Total_Yes <- sum(res_clean$Votes_Yes)
Total_No  <- sum(res_clean$Votes_No)
```

Percentage voting for the changes.

```{r}
Perc_Yes <- 100*Total_Yes / (Total_Yes + Total_No)
Perc_Yes
```

Compute the percentages again (more dp):

```{r}
res_clean <- res_clean %>%
  mutate(Perc_Yes = 100*Votes_Yes / (Votes_Yes + Votes_No))
```

### Results

```{r}
res_clean %>%
  arrange(Perc_Yes) %>%
  kable(align="lrrr", digits = 1)
```


```{r}
hist(res_clean$Perc_Yes, main = "", xlab = "Percentage voting Yes")
```

```{r}
qq_res <- qqPlot(res_clean$Perc_Yes, id = list(labels = res_clean$Region),
                 xlab = "Quantiles (normal distribution)",
                 ylab = "Percentage voting Yes")
```


## Plot on a map

The CRAN version of `raster` didn't work this end (error loading a DLL), so grab from github...

```{r eval = F}
#library(devtools)
#install_github("rspatial/raster")
```

... and load:

```{r message=FALSE, warning=FALSE}
library(raster)
```

Get the Russia country map:

```{r}
ru <- getData("GADM", country = "RUS", level=1)
```


### Matching the region names

Here are the region names in this map (first 10):

```{r}
ru@data$NAME_1[1:10]
```

They're different to the names in the Wikipedia table. How do we match them...?

Fuzzy matching by [edit distance](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/adist.html)...? This almost works for most of them but not quite...

```{r}
distances <- adist(gsub("Oblast|Krai|Okrug|Autonomous",
                        "",
                        res_clean$Region),
                   ru@data$NAME_1)
rownames(distances) <- res_clean$Region
colnames(distances) <- ru@data$NAME_1
```

Often the match is good or close. Other times not so close, e.g., "Sakha" and "Yakutia" are [different names for the same place](https://en.wikipedia.org/wiki/Sakha) but aren't the closest match by edit distance. So, time to export and fix manually:

```{r}
write.csv(as.data.frame(distances), "distances.csv", row.names = T)
```

I fiddled with this file outside R (using... Excel, for shame) and replaced the best match with -1. Reading in again:

```{r}
region_match <- read_csv("fixed_distances.csv")
```

Okay, make a lookup table using a DIRTY for-loop:

```{r}
wiki_region <- region_match$Region
GADM_region <- rep(NA, length(wiki_region))

for (r in 1:nrow(region_match)) {
  row            <- region_match[r,-1]
  matching_index <- which(row == -1)
  GADM_region[r] <- ifelse(length(matching_index) == 1,
                           colnames(row[which(row == -1)]),
                           NA)
}

matched_region_names <- data.frame(wiki_region, GADM_region)
rm(wiki_region, GADM_region, row, matching_index)
```

Take a look:

```{r eval = F}
View(matched_region_names)
```

No matches for Baikonur (the cosmodrome), Crimea or Sevastopol (which are Ukraine), or "Russians abroad" (that ain't an oblast).


### Glue together

```{r}
for_merge <- matched_region_names
names(for_merge)[1] <- "Region"
for_map <- left_join(res_clean, for_merge)
```
Now select the bits we want to plot on a map:

```{r}
for_map <- for_map %>%
  dplyr::select(GADM_region, Perc_Yes)
names(for_map)[1] = "id"
```


### Plot a map

This was more complicated than surely it needs to be...

```{r message=FALSE, warning=FALSE}
library(broom)
library(gpclib)
library(maptools)
library(mapproj)
gpclibPermit()
ru_df <- tidy(ru, region = "NAME_1")
```
This doesn't look good: "support for gpclib will be withdrawn from maptools at the next major release"


```{r}
head(ru_df)
```

```{r}
ru_df_vals <- left_join(ru_df, for_map)
ru_df_vals$region <- ru_df_vals$id # to prevent a message later...
```


### Now really (really) plot the data

```{r warning=FALSE}
ggplot(ru_df_vals, aes(long, lat)) +
  geom_map(map = ru_df_vals,
           aes(map_id = id, fill = Perc_Yes),
           show.legend = T) +
  theme_void() +
  coord_map("azequalarea") + 
  xlim(15,190) +
  ylim(40,83) +
  labs(fill = "% voting yes") +
  scale_fill_viridis(option = "magma", direction = -1)
```

The `xlim`, `ylim` and `coord_map` options were helped along by a [stack overflow post](https://stackoverflow.com/a/37567832/416656).


